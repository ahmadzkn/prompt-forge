{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# âš¡ PromptForge: The Ultimate Prompt Optimizer (Colab Edition)\n",
                "\n",
                "Welcome to the cloud version of PromptForge! This notebook allows you to use the powerful meta-prompting engine entirely in your browser using **Google Colab**.\n",
                "\n",
                "### Supported Backends in Colab:\n",
                "- **OpenAI / Remote**: Connect to OpenAI API.\n",
                "- **Anthropic**: Use Claude 3 models.\n",
                "- **Google Gemini**: Use Gemini 1.5 models.\n",
                "- **Groq**: Ultra-fast Llama 3 inference.\n",
                "\n",
                "*(Note: Local backends like LM Studio and Ollama accessible via localhost are not supported here unless you set up tunneling)*"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 1. Install Dependencies & Clone Repo\n",
                "!git clone https://github.com/ahmadzkn/prompt-forge.git\n",
                "%cd prompt-forge\n",
                "\n",
                "# Install core requirements (excluding GUI libs like customtkinter which don't work in Colab)\n",
                "!pip install openai anthropic google-generativeai groq sqlalchemy pydantic ipywidgets ollama llama-cpp-python"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 2. Initialize Optimizer\n",
                "import sys\n",
                "import os\n",
                "sys.path.append(os.getcwd())\n",
                "\n",
                "from src.optimizer import PromptOptimizer\n",
                "from src.backends.factory import ProviderFactory\n",
                "from src.utils.credential_manager import CredentialManager\n",
                "\n",
                "# Mock keyring for Colab since system keyring isn't available\n",
                "import keyring\n",
                "from keyring.backend import KeyringBackend\n",
                "class ColabKeyring(KeyringBackend):\n",
                "    def set_password(self, service, username, password):\n",
                "        os.environ[f\"{service}_{username}\"] = password\n",
                "    def get_password(self, service, username):\n",
                "        return os.environ.get(f\"{service}_{username}\")\n",
                "    def delete_password(self, service, username):\n",
                "        pass\n",
                "    def priority(self):\n",
                "        return 1\n",
                "\n",
                "keyring.set_keyring(ColabKeyring())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 3. Run PromptForge UI\n",
                "import ipywidgets as widgets\n",
                "from IPython.display import display, clear_output\n",
                "import json\n",
                "\n",
                "# Widgets\n",
                "backend_dropdown = widgets.Dropdown(\n",
                "    options=['OpenAI', 'Anthropic', 'Google Gemini', 'Groq'],\n",
                "    value='Groq',\n",
                "    description='Backend:',\n",
                ")\n",
                "\n",
                "api_key_input = widgets.Password(\n",
                "    placeholder='Enter API Key',\n",
                "    description='API Key:',\n",
                ")\n",
                "\n",
                "model_input = widgets.Text(\n",
                "    value='',\n",
                "    placeholder='Model Name (e.g. llama3-70b-8192)',\n",
                "    description='Model:',\n",
                ")\n",
                "\n",
                "raw_prompt_area = widgets.Textarea(\n",
                "    placeholder='Enter your raw prompt here...',\n",
                "    description='Raw Prompt:',\n",
                "    layout=widgets.Layout(width='100%', height='150px')\n",
                ")\n",
                "\n",
                "optimize_btn = widgets.Button(\n",
                "    description='Optimize Prompt',\n",
                "    button_style='primary',\n",
                "    icon='magic'\n",
                ")\n",
                "\n",
                "output_area = widgets.Output()\n",
                "\n",
                "def on_optimize(b):\n",
                "    with output_area:\n",
                "        clear_output()\n",
                "        print(\"Optimizing... Please wait.\")\n",
                "        \n",
                "        backend_map = {\n",
                "            'OpenAI': 'openai',\n",
                "            'Anthropic': 'anthropic',\n",
                "            'Google Gemini': 'gemini',\n",
                "            'Groq': 'groq'\n",
                "        }\n",
                "        \n",
                "        provider_type = backend_map[backend_dropdown.value]\n",
                "        api_key = api_key_input.value\n",
                "        model = model_input.value\n",
                "        raw_prompt = raw_prompt_area.value\n",
                "        \n",
                "        if not api_key:\n",
                "            print(\"Error: Please enter an API Key.\")\n",
                "            return\n",
                "            \n",
                "        try:\n",
                "            kwargs = {\"api_key\": api_key}\n",
                "            if provider_type == 'openai':\n",
                "                kwargs['base_url'] = \"https://api.openai.com/v1\" # Default to real OpenAI\n",
                "            \n",
                "            optimizer = PromptOptimizer(provider_type=provider_type, **kwargs)\n",
                "            \n",
                "            # If model is empty, try to auto-fetch or set default\n",
                "            if not model:\n",
                "                models = optimizer.get_available_models()\n",
                "                if models:\n",
                "                    model = models[0]\n",
                "                    print(f\"Auto-selected model: {model}\")\n",
                "                else:\n",
                "                    print(\"Error: Could not fetch models. Please specify one manually.\")\n",
                "                    return\n",
                "            \n",
                "            result = optimizer.optimize_prompt(raw_prompt, model)\n",
                "            \n",
                "            clear_output()\n",
                "            \n",
                "            if \"error\" in result:\n",
                "                print(f\"Error: {result['error']}\")\n",
                "                return\n",
                "                \n",
                "            print(f\"### Final Optimized Prompt (Backend: {backend_dropdown.value} / {model})\")\n",
                "            print(\"-\" * 80)\n",
                "            print(result.get(\"final_prompt\", \"No result\"))\n",
                "            print(\"-\" * 80)\n",
                "            \n",
                "            print(\"\\n### Structured Elements:\")\n",
                "            elements = result.get(\"elements\", {})\n",
                "            for k, v in elements.items():\n",
                "                print(f\"**{k.title()}**: {v}\")\n",
                "\n",
                "        except Exception as e:\n",
                "            print(f\"Unexpected Error: {e}\")\n",
                "\n",
                "optimize_btn.on_click(on_optimize)\n",
                "\n",
                "display(widgets.VBox([\n",
                "    widgets.HTML(\"<h2>PromptForge Configuration</h2>\"),\n",
                "    backend_dropdown,\n",
                "    api_key_input,\n",
                "    model_input,\n",
                "    widgets.HTML(\"<h2>Input</h2>\"),\n",
                "    raw_prompt_area,\n",
                "    optimize_btn,\n",
                "    widgets.HTML(\"<h2>Output</h2>\"),\n",
                "    output_area\n",
                "]))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}